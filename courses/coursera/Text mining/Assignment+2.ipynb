{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.0** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Introduction to NLTK\n",
    "\n",
    "In part 1 of this assignment you will use nltk to explore the Herman Melville novel Moby Dick. Then in part 2 you will create a spelling recommender function that uses nltk to find words similar to the misspelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Analyzing Moby Dick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package genesis to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package genesis is already up-to-date!\n",
      "[nltk_data] Downloading package inaugural to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package inaugural is already up-to-date!\n",
      "[nltk_data] Downloading package nps_chat to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package nps_chat is already up-to-date!\n",
      "[nltk_data] Downloading package webtext to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package webtext is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('genesis')\n",
    "nltk.download('inaugural')\n",
    "nltk.download('nps_chat')\n",
    "nltk.download('webtext')\n",
    "nltk.download('treebank')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.book import *\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import words\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "# If you would like to work with the raw text you can use 'moby_raw'\n",
    "with open('moby.txt', 'r') as f:\n",
    "    moby_raw = f.read()\n",
    "    \n",
    "# If you would like to work with the novel in nltk.Text format you can use 'text1'\n",
    "moby_tokens = nltk.word_tokenize(moby_raw)\n",
    "text1 = nltk.Text(moby_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "How many tokens (words and punctuation symbols) are in text1?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Moby',\n",
       " 'Dick',\n",
       " 'by',\n",
       " 'Herman',\n",
       " 'Melville',\n",
       " '1851',\n",
       " ']',\n",
       " 'ETYMOLOGY',\n",
       " '.',\n",
       " '(',\n",
       " 'Supplied',\n",
       " 'by',\n",
       " 'a',\n",
       " 'Late',\n",
       " 'Consumptive',\n",
       " 'Usher',\n",
       " 'to',\n",
       " 'a',\n",
       " 'Grammar',\n",
       " 'School',\n",
       " ')',\n",
       " 'The',\n",
       " 'pale',\n",
       " 'Usher',\n",
       " '--',\n",
       " 'threadbare',\n",
       " 'in',\n",
       " 'coat',\n",
       " ',',\n",
       " 'heart',\n",
       " ',',\n",
       " 'body',\n",
       " ',',\n",
       " 'and',\n",
       " 'brain',\n",
       " ';',\n",
       " 'I',\n",
       " 'see',\n",
       " 'him',\n",
       " 'now',\n",
       " '.',\n",
       " 'He',\n",
       " 'was',\n",
       " 'ever',\n",
       " 'dusting',\n",
       " 'his',\n",
       " 'old',\n",
       " 'lexicons',\n",
       " 'and',\n",
       " 'grammars',\n",
       " ',',\n",
       " 'with',\n",
       " 'a',\n",
       " 'queer',\n",
       " 'handkerchief',\n",
       " ',',\n",
       " 'mockingly',\n",
       " 'embellished',\n",
       " 'with',\n",
       " 'all',\n",
       " 'the',\n",
       " 'gay',\n",
       " 'flags',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'known',\n",
       " 'nations',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " '.',\n",
       " 'He',\n",
       " 'loved',\n",
       " 'to',\n",
       " 'dust',\n",
       " 'his',\n",
       " 'old',\n",
       " 'grammars',\n",
       " ';',\n",
       " 'it',\n",
       " 'somehow',\n",
       " 'mildly',\n",
       " 'reminded',\n",
       " 'him',\n",
       " 'of',\n",
       " 'his',\n",
       " 'mortality',\n",
       " '.',\n",
       " '``',\n",
       " 'While',\n",
       " 'you',\n",
       " 'take',\n",
       " 'in',\n",
       " 'hand',\n",
       " 'to',\n",
       " 'school',\n",
       " 'others',\n",
       " ',',\n",
       " 'and',\n",
       " 'to',\n",
       " 'teach',\n",
       " 'them',\n",
       " 'by',\n",
       " 'what',\n",
       " 'name',\n",
       " 'a',\n",
       " 'whale-fish',\n",
       " 'is',\n",
       " 'to',\n",
       " 'be',\n",
       " 'called',\n",
       " 'in',\n",
       " 'our',\n",
       " 'tongue',\n",
       " 'leaving',\n",
       " 'out',\n",
       " ',',\n",
       " 'through',\n",
       " 'ignorance',\n",
       " ',',\n",
       " 'the',\n",
       " 'letter',\n",
       " 'H',\n",
       " ',',\n",
       " 'which',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'maketh',\n",
       " 'the',\n",
       " 'signification',\n",
       " 'of',\n",
       " 'the',\n",
       " 'word',\n",
       " ',',\n",
       " 'you',\n",
       " 'deliver',\n",
       " 'that',\n",
       " 'which',\n",
       " 'is',\n",
       " 'not',\n",
       " 'true',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'HACKLUYT',\n",
       " \"''\",\n",
       " 'WHALE',\n",
       " '.',\n",
       " '...',\n",
       " 'Sw.',\n",
       " 'and',\n",
       " 'Dan',\n",
       " '.',\n",
       " 'HVAL',\n",
       " '.',\n",
       " 'This',\n",
       " 'animal',\n",
       " 'is',\n",
       " 'named',\n",
       " 'from',\n",
       " 'roundness',\n",
       " 'or',\n",
       " 'rolling',\n",
       " ';',\n",
       " 'for',\n",
       " 'in',\n",
       " 'Dan',\n",
       " '.',\n",
       " 'HVALT',\n",
       " 'is',\n",
       " 'arched',\n",
       " 'or',\n",
       " 'vaulted',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " \"WEBSTER'S\",\n",
       " 'DICTIONARY',\n",
       " \"''\",\n",
       " 'WHALE',\n",
       " '.',\n",
       " '...',\n",
       " 'It',\n",
       " 'is',\n",
       " 'more',\n",
       " 'immediately',\n",
       " 'from',\n",
       " 'the',\n",
       " 'Dut',\n",
       " '.',\n",
       " 'and',\n",
       " 'Ger',\n",
       " '.',\n",
       " 'WALLEN',\n",
       " ';',\n",
       " 'A.S.',\n",
       " 'WALW-IAN',\n",
       " ',',\n",
       " 'to',\n",
       " 'roll',\n",
       " ',',\n",
       " 'to',\n",
       " 'wallow',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'RICHARDSON',\n",
       " \"'S\",\n",
       " 'DICTIONARY',\n",
       " 'KETOS',\n",
       " ',',\n",
       " 'GREEK',\n",
       " '.',\n",
       " 'CETUS',\n",
       " ',',\n",
       " 'LATIN',\n",
       " '.',\n",
       " 'WHOEL',\n",
       " ',',\n",
       " 'ANGLO-SAXON',\n",
       " '.',\n",
       " 'HVALT',\n",
       " ',',\n",
       " 'DANISH',\n",
       " '.',\n",
       " 'WAL',\n",
       " ',',\n",
       " 'DUTCH',\n",
       " '.',\n",
       " 'HWAL',\n",
       " ',',\n",
       " 'SWEDISH',\n",
       " '.',\n",
       " 'WHALE',\n",
       " ',',\n",
       " 'ICELANDIC',\n",
       " '.',\n",
       " 'WHALE',\n",
       " ',',\n",
       " 'ENGLISH',\n",
       " '.',\n",
       " 'BALEINE',\n",
       " ',',\n",
       " 'FRENCH',\n",
       " '.',\n",
       " 'BALLENA',\n",
       " ',',\n",
       " 'SPANISH',\n",
       " '.',\n",
       " 'PEKEE-NUEE-NUEE',\n",
       " ',',\n",
       " 'FEGEE',\n",
       " '.',\n",
       " 'PEKEE-NUEE-NUEE',\n",
       " ',',\n",
       " 'ERROMANGOAN',\n",
       " '.',\n",
       " 'EXTRACTS',\n",
       " '(',\n",
       " 'Supplied',\n",
       " 'by',\n",
       " 'a',\n",
       " 'Sub-Sub-Librarian',\n",
       " ')',\n",
       " '.',\n",
       " 'It',\n",
       " 'will',\n",
       " 'be',\n",
       " 'seen',\n",
       " 'that',\n",
       " 'this',\n",
       " 'mere',\n",
       " 'painstaking',\n",
       " 'burrower',\n",
       " 'and',\n",
       " 'grub-worm',\n",
       " 'of',\n",
       " 'a',\n",
       " 'poor',\n",
       " 'devil',\n",
       " 'of',\n",
       " 'a',\n",
       " 'Sub-Sub',\n",
       " 'appears',\n",
       " 'to',\n",
       " 'have',\n",
       " 'gone',\n",
       " 'through',\n",
       " 'the',\n",
       " 'long',\n",
       " 'Vaticans',\n",
       " 'and',\n",
       " 'street-stalls',\n",
       " 'of',\n",
       " 'the',\n",
       " 'earth',\n",
       " ',',\n",
       " 'picking',\n",
       " 'up',\n",
       " 'whatever',\n",
       " 'random',\n",
       " 'allusions',\n",
       " 'to',\n",
       " 'whales',\n",
       " 'he',\n",
       " 'could',\n",
       " 'anyways',\n",
       " 'find',\n",
       " 'in',\n",
       " 'any',\n",
       " 'book',\n",
       " 'whatsoever',\n",
       " ',',\n",
       " 'sacred',\n",
       " 'or',\n",
       " 'profane',\n",
       " '.',\n",
       " 'Therefore',\n",
       " 'you',\n",
       " 'must',\n",
       " 'not',\n",
       " ',',\n",
       " 'in',\n",
       " 'every',\n",
       " 'case',\n",
       " 'at',\n",
       " 'least',\n",
       " ',',\n",
       " 'take',\n",
       " 'the',\n",
       " 'higgledy-piggledy',\n",
       " 'whale',\n",
       " 'statements',\n",
       " ',',\n",
       " 'however',\n",
       " 'authentic',\n",
       " ',',\n",
       " 'in',\n",
       " 'these',\n",
       " 'extracts',\n",
       " ',',\n",
       " 'for',\n",
       " 'veritable',\n",
       " 'gospel',\n",
       " 'cetology',\n",
       " '.',\n",
       " 'Far',\n",
       " 'from',\n",
       " 'it',\n",
       " '.',\n",
       " 'As',\n",
       " 'touching',\n",
       " 'the',\n",
       " 'ancient',\n",
       " 'authors',\n",
       " 'generally',\n",
       " ',',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'the',\n",
       " 'poets',\n",
       " 'here',\n",
       " 'appearing',\n",
       " ',',\n",
       " 'these',\n",
       " 'extracts',\n",
       " 'are',\n",
       " 'solely',\n",
       " 'valuable',\n",
       " 'or',\n",
       " 'entertaining',\n",
       " ',',\n",
       " 'as',\n",
       " 'affording',\n",
       " 'a',\n",
       " 'glancing',\n",
       " 'bird',\n",
       " \"'s\",\n",
       " 'eye',\n",
       " 'view',\n",
       " 'of',\n",
       " 'what',\n",
       " 'has',\n",
       " 'been',\n",
       " 'promiscuously',\n",
       " 'said',\n",
       " ',',\n",
       " 'thought',\n",
       " ',',\n",
       " 'fancied',\n",
       " ',',\n",
       " 'and',\n",
       " 'sung',\n",
       " 'of',\n",
       " 'Leviathan',\n",
       " ',',\n",
       " 'by',\n",
       " 'many',\n",
       " 'nations',\n",
       " 'and',\n",
       " 'generations',\n",
       " ',',\n",
       " 'including',\n",
       " 'our',\n",
       " 'own',\n",
       " '.',\n",
       " 'So',\n",
       " 'fare',\n",
       " 'thee',\n",
       " 'well',\n",
       " ',',\n",
       " 'poor',\n",
       " 'devil',\n",
       " 'of',\n",
       " 'a',\n",
       " 'Sub-Sub',\n",
       " ',',\n",
       " 'whose',\n",
       " 'commentator',\n",
       " 'I',\n",
       " 'am',\n",
       " '.',\n",
       " 'Thou',\n",
       " 'belongest',\n",
       " 'to',\n",
       " 'that',\n",
       " 'hopeless',\n",
       " ',',\n",
       " 'sallow',\n",
       " 'tribe',\n",
       " 'which',\n",
       " 'no',\n",
       " 'wine',\n",
       " 'of',\n",
       " 'this',\n",
       " 'world',\n",
       " 'will',\n",
       " 'ever',\n",
       " 'warm',\n",
       " ';',\n",
       " 'and',\n",
       " 'for',\n",
       " 'whom',\n",
       " 'even',\n",
       " 'Pale',\n",
       " 'Sherry',\n",
       " 'would',\n",
       " 'be',\n",
       " 'too',\n",
       " 'rosy-strong',\n",
       " ';',\n",
       " 'but',\n",
       " 'with',\n",
       " 'whom',\n",
       " 'one',\n",
       " 'sometimes',\n",
       " 'loves',\n",
       " 'to',\n",
       " 'sit',\n",
       " ',',\n",
       " 'and',\n",
       " 'feel',\n",
       " 'poor-devilish',\n",
       " ',',\n",
       " 'too',\n",
       " ';',\n",
       " 'and',\n",
       " 'grow',\n",
       " 'convivial',\n",
       " 'upon',\n",
       " 'tears',\n",
       " ';',\n",
       " 'and',\n",
       " 'say',\n",
       " 'to',\n",
       " 'them',\n",
       " 'bluntly',\n",
       " ',',\n",
       " 'with',\n",
       " 'full',\n",
       " 'eyes',\n",
       " 'and',\n",
       " 'empty',\n",
       " 'glasses',\n",
       " ',',\n",
       " 'and',\n",
       " 'in',\n",
       " 'not',\n",
       " 'altogether',\n",
       " 'unpleasant',\n",
       " 'sadness',\n",
       " '--',\n",
       " 'Give',\n",
       " 'it',\n",
       " 'up',\n",
       " ',',\n",
       " 'Sub-Subs',\n",
       " '!',\n",
       " 'For',\n",
       " 'by',\n",
       " 'how',\n",
       " 'much',\n",
       " 'the',\n",
       " 'more',\n",
       " 'pains',\n",
       " 'ye',\n",
       " 'take',\n",
       " 'to',\n",
       " 'please',\n",
       " 'the',\n",
       " 'world',\n",
       " ',',\n",
       " 'by',\n",
       " 'so',\n",
       " 'much',\n",
       " 'the',\n",
       " 'more',\n",
       " 'shall',\n",
       " 'ye',\n",
       " 'for',\n",
       " 'ever',\n",
       " 'go',\n",
       " 'thankless',\n",
       " '!',\n",
       " 'Would',\n",
       " 'that',\n",
       " 'I',\n",
       " 'could',\n",
       " 'clear',\n",
       " 'out',\n",
       " 'Hampton',\n",
       " 'Court',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Tuileries',\n",
       " 'for',\n",
       " 'ye',\n",
       " '!',\n",
       " 'But',\n",
       " 'gulp',\n",
       " 'down',\n",
       " 'your',\n",
       " 'tears',\n",
       " 'and',\n",
       " 'hie',\n",
       " 'aloft',\n",
       " 'to',\n",
       " 'the',\n",
       " 'royal-mast',\n",
       " 'with',\n",
       " 'your',\n",
       " 'hearts',\n",
       " ';',\n",
       " 'for',\n",
       " 'your',\n",
       " 'friends',\n",
       " 'who',\n",
       " 'have',\n",
       " 'gone',\n",
       " 'before',\n",
       " 'are',\n",
       " 'clearing',\n",
       " 'out',\n",
       " 'the',\n",
       " 'seven-storied',\n",
       " 'heavens',\n",
       " ',',\n",
       " 'and',\n",
       " 'making',\n",
       " 'refugees',\n",
       " 'of',\n",
       " 'long-pampered',\n",
       " 'Gabriel',\n",
       " ',',\n",
       " 'Michael',\n",
       " ',',\n",
       " 'and',\n",
       " 'Raphael',\n",
       " ',',\n",
       " 'against',\n",
       " 'your',\n",
       " 'coming',\n",
       " '.',\n",
       " 'Here',\n",
       " 'ye',\n",
       " 'strike',\n",
       " 'but',\n",
       " 'splintered',\n",
       " 'hearts',\n",
       " 'together',\n",
       " '--',\n",
       " 'there',\n",
       " ',',\n",
       " 'ye',\n",
       " 'shall',\n",
       " 'strike',\n",
       " 'unsplinterable',\n",
       " 'glasses',\n",
       " '!',\n",
       " 'EXTRACTS',\n",
       " '.',\n",
       " '``',\n",
       " 'And',\n",
       " 'God',\n",
       " 'created',\n",
       " 'great',\n",
       " 'whales',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'GENESIS',\n",
       " '.',\n",
       " '``',\n",
       " 'Leviathan',\n",
       " 'maketh',\n",
       " 'a',\n",
       " 'path',\n",
       " 'to',\n",
       " 'shine',\n",
       " 'after',\n",
       " 'him',\n",
       " ';',\n",
       " 'One',\n",
       " 'would',\n",
       " 'think',\n",
       " 'the',\n",
       " 'deep',\n",
       " 'to',\n",
       " 'be',\n",
       " 'hoary',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'JOB',\n",
       " '.',\n",
       " '``',\n",
       " 'Now',\n",
       " 'the',\n",
       " 'Lord',\n",
       " 'had',\n",
       " 'prepared',\n",
       " 'a',\n",
       " 'great',\n",
       " 'fish',\n",
       " 'to',\n",
       " 'swallow',\n",
       " 'up',\n",
       " 'Jonah',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'JONAH',\n",
       " '.',\n",
       " '``',\n",
       " 'There',\n",
       " 'go',\n",
       " 'the',\n",
       " 'ships',\n",
       " ';',\n",
       " 'there',\n",
       " 'is',\n",
       " 'that',\n",
       " 'Leviathan',\n",
       " 'whom',\n",
       " 'thou',\n",
       " 'hast',\n",
       " 'made',\n",
       " 'to',\n",
       " 'play',\n",
       " 'therein',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'PSALMS',\n",
       " '.',\n",
       " '``',\n",
       " 'In',\n",
       " 'that',\n",
       " 'day',\n",
       " ',',\n",
       " 'the',\n",
       " 'Lord',\n",
       " 'with',\n",
       " 'his',\n",
       " 'sore',\n",
       " ',',\n",
       " 'and',\n",
       " 'great',\n",
       " ',',\n",
       " 'and',\n",
       " 'strong',\n",
       " 'sword',\n",
       " ',',\n",
       " 'shall',\n",
       " 'punish',\n",
       " 'Leviathan',\n",
       " 'the',\n",
       " 'piercing',\n",
       " 'serpent',\n",
       " ',',\n",
       " 'even',\n",
       " 'Leviathan',\n",
       " 'that',\n",
       " 'crooked',\n",
       " 'serpent',\n",
       " ';',\n",
       " 'and',\n",
       " 'he',\n",
       " 'shall',\n",
       " 'slay',\n",
       " 'the',\n",
       " 'dragon',\n",
       " 'that',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'sea',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'ISAIAH',\n",
       " \"''\",\n",
       " 'And',\n",
       " 'what',\n",
       " 'thing',\n",
       " 'soever',\n",
       " 'besides',\n",
       " 'cometh',\n",
       " 'within',\n",
       " 'the',\n",
       " 'chaos',\n",
       " 'of',\n",
       " 'this',\n",
       " 'monster',\n",
       " \"'s\",\n",
       " 'mouth',\n",
       " ',',\n",
       " 'be',\n",
       " 'it',\n",
       " 'beast',\n",
       " ',',\n",
       " 'boat',\n",
       " ',',\n",
       " 'or',\n",
       " 'stone',\n",
       " ',',\n",
       " 'down',\n",
       " 'it',\n",
       " 'goes',\n",
       " 'all',\n",
       " 'incontinently',\n",
       " 'that',\n",
       " 'foul',\n",
       " 'great',\n",
       " 'swallow',\n",
       " 'of',\n",
       " 'his',\n",
       " ',',\n",
       " 'and',\n",
       " 'perisheth',\n",
       " 'in',\n",
       " 'the',\n",
       " 'bottomless',\n",
       " 'gulf',\n",
       " 'of',\n",
       " 'his',\n",
       " 'paunch',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'HOLLAND',\n",
       " \"'S\",\n",
       " 'PLUTARCH',\n",
       " \"'S\",\n",
       " 'MORALS',\n",
       " '.',\n",
       " '``',\n",
       " 'The',\n",
       " 'Indian',\n",
       " 'Sea',\n",
       " 'breedeth',\n",
       " 'the',\n",
       " 'most',\n",
       " 'and',\n",
       " 'the',\n",
       " 'biggest',\n",
       " 'fishes',\n",
       " 'that',\n",
       " 'are',\n",
       " ':',\n",
       " 'among',\n",
       " 'which',\n",
       " 'the',\n",
       " 'Whales',\n",
       " 'and',\n",
       " 'Whirlpooles',\n",
       " 'called',\n",
       " 'Balaene',\n",
       " ',',\n",
       " 'take',\n",
       " 'up',\n",
       " 'as',\n",
       " 'much',\n",
       " 'in',\n",
       " 'length',\n",
       " 'as',\n",
       " 'four',\n",
       " 'acres',\n",
       " 'or',\n",
       " 'arpens',\n",
       " 'of',\n",
       " 'land',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'HOLLAND',\n",
       " \"'S\",\n",
       " 'PLINY',\n",
       " '.',\n",
       " '``',\n",
       " 'Scarcely',\n",
       " 'had',\n",
       " 'we',\n",
       " 'proceeded',\n",
       " 'two',\n",
       " 'days',\n",
       " 'on',\n",
       " 'the',\n",
       " 'sea',\n",
       " ',',\n",
       " 'when',\n",
       " 'about',\n",
       " 'sunrise',\n",
       " 'a',\n",
       " 'great',\n",
       " 'many',\n",
       " 'Whales',\n",
       " 'and',\n",
       " 'other',\n",
       " 'monsters',\n",
       " 'of',\n",
       " 'the',\n",
       " 'sea',\n",
       " ',',\n",
       " 'appeared',\n",
       " '.',\n",
       " 'Among',\n",
       " 'the',\n",
       " 'former',\n",
       " ',',\n",
       " 'one',\n",
       " 'was',\n",
       " 'of',\n",
       " 'a',\n",
       " 'most',\n",
       " 'monstrous',\n",
       " 'size',\n",
       " '.',\n",
       " '...',\n",
       " 'This',\n",
       " 'came',\n",
       " 'towards',\n",
       " 'us',\n",
       " ',',\n",
       " 'open-mouthed',\n",
       " ',',\n",
       " 'raising',\n",
       " 'the',\n",
       " 'waves',\n",
       " 'on',\n",
       " 'all',\n",
       " 'sides',\n",
       " ',',\n",
       " 'and',\n",
       " 'beating',\n",
       " 'the',\n",
       " 'sea',\n",
       " 'before',\n",
       " 'him',\n",
       " 'into',\n",
       " 'a',\n",
       " 'foam',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'TOOKE',\n",
       " \"'S\",\n",
       " 'LUCIAN',\n",
       " '.',\n",
       " '``',\n",
       " 'THE',\n",
       " 'TRUE',\n",
       " 'HISTORY',\n",
       " '.',\n",
       " \"''\",\n",
       " '``',\n",
       " 'He',\n",
       " 'visited',\n",
       " 'this',\n",
       " 'country',\n",
       " 'also',\n",
       " 'with',\n",
       " 'a',\n",
       " 'view',\n",
       " 'of',\n",
       " 'catching',\n",
       " 'horse-whales',\n",
       " ',',\n",
       " 'which',\n",
       " 'had',\n",
       " 'bones',\n",
       " 'of',\n",
       " 'very',\n",
       " 'great',\n",
       " 'value',\n",
       " 'for',\n",
       " 'their',\n",
       " 'teeth',\n",
       " ',',\n",
       " 'of',\n",
       " 'which',\n",
       " 'he',\n",
       " 'brought',\n",
       " 'some',\n",
       " 'to',\n",
       " 'the',\n",
       " 'king',\n",
       " '.',\n",
       " '...',\n",
       " 'The',\n",
       " 'best',\n",
       " 'whales',\n",
       " 'were',\n",
       " 'catched',\n",
       " 'in',\n",
       " 'his',\n",
       " 'own',\n",
       " 'country',\n",
       " ',',\n",
       " 'of',\n",
       " 'which',\n",
       " 'some',\n",
       " 'were',\n",
       " 'forty-eight',\n",
       " ',',\n",
       " 'some',\n",
       " 'fifty',\n",
       " 'yards',\n",
       " 'long',\n",
       " '.',\n",
       " 'He',\n",
       " 'said',\n",
       " 'that',\n",
       " 'he',\n",
       " 'was',\n",
       " 'one',\n",
       " 'of',\n",
       " 'six',\n",
       " 'who',\n",
       " 'had',\n",
       " 'killed',\n",
       " 'sixty',\n",
       " 'in',\n",
       " 'two',\n",
       " 'days',\n",
       " '.',\n",
       " \"''\",\n",
       " '--',\n",
       " 'OTHER',\n",
       " 'OR',\n",
       " 'OCTHER',\n",
       " \"'S\",\n",
       " 'VERBAL',\n",
       " 'NARRATIVE',\n",
       " 'TAKEN',\n",
       " 'DOWN',\n",
       " 'FROM',\n",
       " 'HIS',\n",
       " 'MOUTH',\n",
       " 'BY',\n",
       " 'KING',\n",
       " 'ALFRED',\n",
       " ',',\n",
       " 'A.D.',\n",
       " '890',\n",
       " '.',\n",
       " '``',\n",
       " 'And',\n",
       " 'whereas',\n",
       " 'all',\n",
       " 'the',\n",
       " 'other',\n",
       " 'things',\n",
       " ',',\n",
       " 'whether',\n",
       " 'beast',\n",
       " 'or',\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(moby_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255018"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def example_one():\n",
    "    \n",
    "    return len(nltk.word_tokenize(moby_raw)) # or alternatively len(text1)\n",
    "\n",
    "example_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "How many unique tokens (unique words and punctuation) does text1 have?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def example_two():\n",
    "    \n",
    "    return len(set(nltk.word_tokenize(moby_raw))) # or alternatively len(set(text1))\n",
    "\n",
    "example_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "\n",
    "After lemmatizing the verbs, how many unique tokens does text1 have?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def example_three():\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = [lemmatizer.lemmatize(w,'v') for w in text1]\n",
    "\n",
    "    return len(set(lemmatized))\n",
    "\n",
    "example_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is the lexical diversity of the given text input? (i.e. ratio of unique tokens to the total number of tokens)\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08139566804842562"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_one():\n",
    "    \n",
    "     return len(set(nltk.word_tokenize(moby_raw)))/len(nltk.word_tokenize(moby_raw))\n",
    "\n",
    "answer_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What percentage of tokens is 'whale'or 'Whale'?\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.050689023802640454"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_two():\n",
    "    \n",
    "    dist = FreqDist(text1)\n",
    "    return len([w for w in text1 if re.search(r'^[Ww]hale$', w)])/len(dist)\n",
    "\n",
    "answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "What are the 20 most frequently occurring (unique) tokens in the text? What is their frequency?\n",
    "\n",
    "*This function should return a list of 20 tuples where each tuple is of the form `(token, frequency)`. The list should be sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 19204),\n",
       " ('the', 13715),\n",
       " ('.', 7308),\n",
       " ('of', 6513),\n",
       " ('and', 6010),\n",
       " ('a', 4545),\n",
       " ('to', 4515),\n",
       " (';', 4173),\n",
       " ('in', 3908),\n",
       " ('that', 2978),\n",
       " ('his', 2459),\n",
       " ('it', 2196),\n",
       " ('I', 2111),\n",
       " ('!', 1767),\n",
       " ('is', 1722),\n",
       " ('--', 1713),\n",
       " ('with', 1659),\n",
       " ('he', 1658),\n",
       " ('was', 1639),\n",
       " ('as', 1620)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_three():\n",
    "    \n",
    "    return sorted(dist.items(), key=lambda x: x[1], reverse=True)[0:20]\n",
    "\n",
    "answer_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "What tokens have a length of greater than 5 and frequency of more than 150?\n",
    "\n",
    "*This function should return an alphabetically sorted list of the tokens that match the above constraints. To sort your list, use `sorted()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Captain',\n",
       " 'Pequod',\n",
       " 'Queequeg',\n",
       " 'Starbuck',\n",
       " 'almost',\n",
       " 'before',\n",
       " 'himself',\n",
       " 'little',\n",
       " 'seemed',\n",
       " 'should',\n",
       " 'though',\n",
       " 'through',\n",
       " 'whales',\n",
       " 'without']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_four():\n",
    "    dist = FreqDist(text1)\n",
    "    return sorted([w for w in dist.keys() if dist[w]>150 and len(w)>5])\n",
    "answer_four()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Find the longest word in text1 and that word's length.\n",
    "\n",
    "*This function should return a tuple `(longest_word, length)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"twelve-o'clock-at-night\", 23)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_five():\n",
    "    max_len = max([len(w) for w in text1])\n",
    "    max_word = [w for w in dist.keys() if len(w)==max_len][0]\n",
    "    return (max_word, max_len)\n",
    "\n",
    "answer_five()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "What unique words have a frequency of more than 2000? What is their frequency?\n",
    "\n",
    "\"Hint:  you may want to use `isalpha()` to check if the token is a word and not punctuation.\"\n",
    "\n",
    "*This function should return a list of tuples of the form `(frequency, word)` sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def answer_six():\n",
    "    dist = FreqDist(text1)\n",
    "    words = [w for w in dist.keys() if str.isalpha(w)]\n",
    "    words2000 = [w for w in words if dist[w]> 2000]\n",
    "    sorted([(w, dist[w]) for w in words2000], key = lambda x:x[1], reverse= True)\n",
    "    return # Your answer here\n",
    "\n",
    "answer_six()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "What is the average number of tokens per sentence?\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.88489646772229"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_seven():\n",
    "    sentence = sent_tokenize(moby_raw)\n",
    "    tokens = [word_tokenize(i) for i in sentence]\n",
    "    numbers = []\n",
    "    for i in tokens:\n",
    "        numbers.append(len(i))\n",
    "    return np.mean(numbers)\n",
    "\n",
    "answer_seven()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "What are the 5 most frequent parts of speech in this text? What is their frequency?\n",
    "\n",
    "*This function should return a list of tuples of the form `(part_of_speech, frequency)` sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_eight():\n",
    "    parts = nltk.pos_tag(text1)\n",
    "    freq = nltk.FreqDist(part for (word, part) in parts)\n",
    "    answer = freq.most_common()[:6]\n",
    "    output = [i for i in answer if i[0]!=',']\n",
    "    output\n",
    "    return # Your answer here\n",
    "\n",
    "answer_eight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Spelling Recommender\n",
    "\n",
    "For this part of the assignment you will create three different spelling recommenders, that each take a list of misspelled words and recommends a correctly spelled word for every word in the list.\n",
    "\n",
    "For every misspelled word, the recommender should find find the word in `correct_spellings` that has the shortest distance*, and starts with the same letter as the misspelled word, and return that word as a recommendation.\n",
    "\n",
    "*Each of the three different recommenders will use a different distance measure (outlined below).\n",
    "\n",
    "Each of the recommenders should provide recommendations for the three default words provided: `['cormulent', 'incendenece', 'validrate']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "\n",
    "correct_spellings = words.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the trigrams of the two words.**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corpulent', 'indecence', 'validate']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_nine(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    word_finder =  words.words()\n",
    "    word_finder = [word_finder[w].lower() for w in range(0, len(word_finder))]\n",
    "\n",
    "    final_list = []\n",
    "    word_symbol = np.array(list(map(lambda x: x[0], word_finder)))\n",
    "\n",
    "    for word in entries:\n",
    "        ind = np.where(word_symbol==word[0])\n",
    "        word_to_compare = np.asarray(word_finder)[ind]\n",
    "    \n",
    "        jd = 1\n",
    "        ngrams0 = set(nltk.ngrams(word,n=3))\n",
    "        for word_com in word_to_compare:\n",
    "            ngrams = set(nltk.ngrams(word_com, n=3))\n",
    "            if nltk.distance.jaccard_distance(ngrams, ngrams0)<jd:\n",
    "                jd = nltk.distance.jaccard_distance(ngrams, ngrams0)\n",
    "                correct_word = word_com\n",
    "\n",
    "        final_list.append(correct_word)\n",
    "\n",
    "\n",
    "    return final_list\n",
    "    \n",
    "answer_nine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the 4-grams of the two words.**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cormus', 'incendiary', 'valid']"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_ten(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    word_finder =  words.words()\n",
    "    word_finder = [word_finder[w].lower() for w in range(0, len(word_finder))]\n",
    "\n",
    "    final_list = []\n",
    "    word_symbol = np.array(list(map(lambda x: x[0], word_finder)))\n",
    "\n",
    "    for word in entries:\n",
    "        ind = np.where(word_symbol==word[0])\n",
    "        word_to_compare = np.asarray(word_finder)[ind]\n",
    "    \n",
    "        jd = 1\n",
    "        ngrams0 = set(nltk.ngrams(word,n=4))\n",
    "        for word_com in word_to_compare:\n",
    "            ngrams = set(nltk.ngrams(word_com, n=4))\n",
    "            if nltk.distance.jaccard_distance(ngrams, ngrams0)<jd:\n",
    "                jd = nltk.distance.jaccard_distance(ngrams, ngrams0)\n",
    "                correct_word = word_com\n",
    "\n",
    "        final_list.append(correct_word)\n",
    "\n",
    "\n",
    "    return final_list\n",
    "    \n",
    "answer_ten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Edit distance on the two words with transpositions.](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance)**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corpulent', 'intendence', 'validate']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_eleven(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    word_finder =  words.words()\n",
    "    word_finder = [word_finder[w].lower() for w in range(0, len(word_finder))]\n",
    "\n",
    "    final_list = []\n",
    "    word_symbol = np.array(list(map(lambda x: x[0], word_finder)))\n",
    "\n",
    "    for word in entries:\n",
    "        ind = np.where(word_symbol==word[0])\n",
    "        word_to_compare = np.asarray(word_finder)[ind]\n",
    "    \n",
    "        jd = 10\n",
    "        for word_com in word_to_compare:\n",
    "            if nltk.distance.edit_distance(word_com, word)<jd:\n",
    "                jd = nltk.distance.edit_distance(word_com, word)\n",
    "                correct_word = word_com\n",
    "\n",
    "        final_list.append(correct_word)\n",
    "\n",
    "\n",
    "    return final_list\n",
    "    \n",
    "answer_eleven()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "r35En",
   "launcher_item_id": "tCVfW",
   "part_id": "NTVgL"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
